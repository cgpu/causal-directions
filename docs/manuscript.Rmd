---
title: "Determining the existance and direction of causality in the face of measurement error"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  pdf_document:
    keep_tex: true
bibliography: manuscript.bib
csl: nature.csl
---

Gibran Hemani*, Kate Tilling and George Davey Smith

MRC Integrative Epidemiology Unit (IEU) at the University of Bristol, School of Social and Community Medicine, Bristol, UK

\* Correspondence to: g.hemani@bristol.ac.uk


```{r setup, echo=FALSE, cache=FALSE}

suppressWarnings(suppressPackageStartupMessages(library(knitr)))
suppressWarnings(suppressPackageStartupMessages(library(pander)))
suppressWarnings(suppressPackageStartupMessages(library(captioner)))
panderOptions("table.caption.prefix", "")

read_chunk("~/repo/cit_measurement_error/scripts/mr_directionality_analysis.R")
opts_chunk$set(warning=FALSE, message=FALSE, cache=TRUE, echo=FALSE)

fig_nums <- captioner()
tab_nums <- captioner(prefix = "Table")
sfig_nums <- captioner(prefix = "Supplementary Figure")
stab_nums <- captioner(prefix = "Supplementary Table")

```


```{r tablelist, cache=FALSE}

ctab <- function(x) tab_nums(x, display="c")

tab_nums(
	"", 
	caption="", 
	display=FALSE)

```

```{r figurelist, cache=FALSE}

cfig <- function(x) fig_nums(x, display="c")

fig_nums(
	"cit_measurement_error_figure", 
	caption="The CIT was performed on simulated variables where the exposure influenced the outcome and the exposure was instrumented by a SNP. The test statistic from CIT when testing if the exposure caused the outcome (the true model) is in red, and the test for the outcome causing the exposure (false model) is in green. Rows of plots represent the sample sizes used for the simulations. As measurement error increases (decreasing values on x-axis) the test statistic for the incorrect model gets stronger and the test statistic for the correct model gets weaker.",
	display=FALSE
)

fig_nums(
	"d_relationship_figure", 
	caption="Plots depicting the function $d = cor(x, x_O) - cor(x,y)cor(y, y_O)$. $d$ is plotted on the y axis, with measurement precision of $x$ ($cor(x,x_O)$) on the x-axis. Higher measurement precision of $y$ ($cor(y,y_O)$) is depicted by lighter coloured lines, and columns of boxes are for different true values of $cor(x,y)$. The graph shows that for the majority of the parameter space of the function, $d$ is positive, especially where causal relationships are relatively weak.",
	display=FALSE
)


fig_nums(
	"causality_exists_tpr",
	caption="Outcomes were simulated to be causally influenced by exposures with varying degrees of measurement imprecision applied to the exposure variable (x axis). True positive rates (y axis) for MR and CIT were compared with for varying levels of measurement imprecision in the outcome variable (rows of boxes) and sample sizes (columns of boxes)."
)

fig_nums(
	"cit_mr_comparison_figure", 
	caption="Outcomes were simulated to be causally influenced by exposures, with varying degrees of measurement error applied to both. CIT and MR were used to infer evidence for causality between the exposure and outcome, and to infer the direction of causality. The value of $d = \\rho_{x, x_O} - \\rho_{x,y}\\rho_{y,y_O}$, such that when $d$ is negative we expect the Steiger test to be more likely to be wrong about the direction of causality. Rows of graphs represent the sample size used in the simulations. For the CIT method, outcome 1 denoted evidence for causality with correct model, outcomes 2 or 3 denoted evidence for causality with incorrect model, and outcome 4 denoted no evidence for causality.",
	display=FALSE
)


```

```{r stablelist, cache=FALSE}

cstab <- function(x) stab_nums(x, display="c")

stab_nums(
	"",
	caption="",
	display=FALSE
)

```

```{r sfigurelist, cache=FALSE}

csfig <- function(x) sfig_nums(x, display="c")

sfig_nums("", 
	caption="", 
	display=FALSE
)

```

```{r load_up }

```
```{r read_data }

```

### Abstract

With our ability to characterize the human phenome ever improving it is becoming increasingly common to use statistical tests to infer the causal relationships between correlated variables. A simple and commonly used method for inferring if an exposure is on the causal pathway to an outcome is through using genetic instruments in mediation analysis, where the effect of an instrument on the outcome is tested before and after adjusting for the exposure. We show that in the face of measurement error this can lead to erroneous results, and that increasing sample size, rather than reducing bias, can often have the effect of increasing certainty in the wrong answer. Commonly used tools that are predicated on this methodology such as the causal inference test (CIT) are shown to be susceptible. We demonstrate that Mendelian randomization (MR) is a method for causal inference that is robust to measurement error, and that a simple extension to MR can provide a method to estimate the direction of causality between correlated variables even when the biology of the instrument is unknown. We argue that because measurement error is ubiquitous in phenotypic data, mediation-based causal inference should be treated with caution.


## Introduction

The last decade has seem a rapid acceleration in technological advances that enable us to measure the human phenome in ever increasing detail, furnishing biologists with the tantalising opportunity to map the molecular basis of complex traits. This does, however, require overcoming the statistical challenge of correctly defining the causal architectures that underlie these high dimensional data. For example, constructing gene networks, identifying metabolic perturbations that lead to disease, or understanding the influence of epigenomic influences on gene expression all depend on understanding the causal nature of any putative observational associations. Despite the ubiquity of the question, commonly used cross-sectional study designs are notoriously susceptible to pitfalls in making causal inference, with simple regression-based techniques unable to distinguish a true causal association from reverse causation or confounding.

An established statistical design that can resolve this problem is randomisation. Given the hypothesis that an exposure is causally related to an outcome, randomisation can be employed to assess the causal nature of the association by randomly splitting the sample into two groups, subjecting one group to the exposure and leaving the other as a control. The association between the exposure and the outcome in this setting provides a robust estimate of the causal relationship. This is the theoretical basis behind randomised control trials, but in practice randomisation is often impossible to implement in an experimental context due to cost, scale or inability to manipulate the exposure. The principle, however, can be employed in extant cross sectional data through the use of genetic variants associated with the exposure (instruments), where the inheritance of an allele serves as a random lifetime allocation of differential exposure levels. Two statistical approaches to exploiting the properties of genetic instruments are commonly used: mediation and Mendelian randomisation (MR)  [@DaveySmith2004; @DaveySmithHemani2014]. 

Mediation is a commonly used statistical method for making causal inference in observational data [@Millstein2009; @Schadt2005; @Gayan2010a; @Tavtigian2009], and it exists in many forms, from simple regression based systems to structural equation modeling (SEM) [@Aten2008]. A mediation analysis seeks to explain the mechanism that underlies an observed relationship between an independent and a dependent variable by introducing a third, 'mediator' variable. If the association between the independent and dependent variables disappears when conditioning on the mediator variable then this provides evidence that the independent variable influences the dependent variable through the mediator. 

This simplistic scenario, however, is seldom borne out in reality. Alternative models of reverse causation or confounding are often indistinguishable from the hypothesised model of the independent variable causing the dependent variable via the mediator. A proposed solution to this is to use a genetic instrument as the independent variable. Supposing an exposure has a causal effect on an outcome, then an ‘instrument’ that causes the exposure (a single nucleotide polymorophism (SNP), for example) should also influence the outcome. Therefore the influence of the instrument on the outcome conditional on the exposure should be zero. This forms the basis of a number of methods, such as the regression-based causal inference test (CIT) [@Millstein2009], an SEM implementation in the NEO software [@Aten2008], and various Bayesian methods. They have been employed by a number of recent publications that make causal inferences, often in large scale ‘omics datasets [@Koestler2014; @Liu2013; @Waszak2015].

MR employs the same data under a completely different model. Here an instrumental variable (typically a SNP) that has a robost, direct association with the exposure is used as a surrogate for the exposure in an association test with the outcome. Here the problems of confounding or reverse causation are avoided by testing for association between the outcome and the SNP. The causal association between the exposure and the outcome can be estimated by scaling the association between the SNP and the outcome by the association between the SNP and the exposure. 

By utilising genetic instruments in different ways, mediation and MR models have properties that confer some advantages and some disadvantages. The main advantage of mediation is that the true underlying biology of the genetic instrument doesn't necessarily need to be known as long as it associates with the putative exposure. In the CIT framework (described fully in the Methods) for example, the test statistic is different if you test for the exposure causing the outcome or the outcome causing the exposure, allowing the researcher to infer the direction of causality between two variables.

Such is not the case for MR, where in order to infer the direction of causality the instrument must be known to influence the exposure directly, associating with the outcome only through the exposure. This requirement can be problematic because if there exists a putative association between two variables, with the instrumental SNP being robustly associated with each, it can be difficult to determine which of the two variables is subject to the direct effect of the SNP (i.e., for which of the two variables is the SNP a valid instrument?). By definition, we expect that if the association is causal then a SNP for the exposure will be associated with the outcome, so if the researcher erroneously uses the SNP as an instrument for the outcome then they are likely to see an apparently robust causal association of outcome on exposure. Such a situation can arise in many scenarios. Genome wide association studies (GWASs) that identify genetic associations for complex traits are, by design, hypothesis free and agnostic of genomic function, and it often takes years of follow up studies to understand the biological nature of a putative GWAS hit [@Claussnitzer2015]. For example, the same FTO variant that is associated with body mass index (BMI) is also associated with C-reactive protein (CRP). It is known that this is because BMI causes CRP [@Timpson2011], but supposing we only had *a priori* knowledge that FTO associated with CRP, and we used it to instrument CRP in an MR analysis of CRP against BMI, we would mistakenly infer that CRP causes BMI. Another situation is where the causal directions between 'omic measures need to be determined, for example if a DNA methylation probe is associated with expression of an adjacent gene, then is a cis-acting SNP an instrument for the DNA methylation level, or the gene expression level [@Waszak2015]? 

MR does however have some important advantages over mediation based approaches. First, MR is used as a tool to not just deduce the existance of causality, but to also estimate the causal effect size. Second, using mediation requires that the exposure, outcome and instrument variables are all measured in the same data, whereas recent extensions to MR relax this assumption, allowing causal inference to be drawn when exposure variables and outcome variables are measured in different samples [@Pierce2013]. This has the crucial advantage of improving statistical power by allowing analysis in much larger sample sizes. Third, and though this is often underappreciated in fields outside classical epidemiology it is of crucial importance, MR is substantially more robust to there being measurement error in the exposure variable. Indeed instrumental variable (IV) analysis was in part initially introduced as a correction for measurement error [@Ashenfelter1994], whereas it has been noted that both basic mediation [@LeCessie2012; @Nagarajan2013; @Shpitser2010; @Blakely2013] and mediation methods that use instrumental variables [@Wang2015; @Lagani2015] are prone to be unreliable in its presence. We argue that this is a serious limitation.

Measurement (or observational) error is the difference between the measured value of a quantity and its true value. Such variability can arise through a whole plethora of mechanisms, which are often unique to the study design and difficult to avoid [@Houle2011; @Hernan2009]. Array technology is now commonly used to obtain high throughput phenotyping at low cost, but they come with the problem of having imperfect resolution, so for example methylation levels as measured by the Illumina450k chip are prone to have some amount of noise around the true value [@Harper2013; @Chen2013a]. Relatedly, if the measurement of biological interest is the methylation level in a T cell, then measurement error of this value can be introduced by using methylation levels from whole blood samples because the measured value will be an assay of many cell types [@Houseman2012].

Measurement error will of course arise in more low-tech data too, for example when measuring BMI one is typically interested in using this as a proxy for adiposity, but it is clear that the correlation between BMI and underlying adiposity is not perfect [@Ahima2013]. A similar problem of biological misspecification is unavoidable in disease diagnosis, and measuring behaviour such as smoking or diet is notoriously difficult to do accurately. Measurement error can also be introduced after the data has been collected, for example the transformation of non-normal data for the purpose of statistical analysis will lead to a new variable that will typically incur both bias and imprecision compared to the original variable. The sources of measurement error are not limited to this list [@Hernan2009], and its impact has been explored in the context of mediation analysis in the epidemiological literature extensively [@LeCessie2012; @Blakely2013].

Given the near-ubiquitous presence of measurement error in biological data it is vital to understand its impact on the tools we use for causal inference. Here we show using theory and simulations how non-differential measurement error and measurement imprecision can lead to unreliable causal inference in the mediation-based CIT method. We also present an extension to MR that allows researchers to ascertain the causal direction even when the biology of the instrument is not fully understood. This improves the utility of MR in cases where mediation based methods might have otherwise been used preferentially.


## Methods

The analysis proceeds by simulating variables that have known causal effects and valid instruments, and then applying measurement error in different configurations. We then assess the performance of the CIT test and MR analysis for a) inference of a causal relationship and b) inferring the correct direction of causality. Included in the MR analysis is a simple extension that is used to make inference of the causal direction when it is unknown which of the correlated variables the instrument is directly acting upon. All analysis was performed using the R programming language [@RCoreTeam2015] and code is made available at [github url to go here]().


### CIT test

The CIT method [@Millstein2009] is implemented in the R package *R/cit* [@Millstein2016]. The methodology of the CIT is as follows. Assume an exposure $x$ is instrumented by a SNP $g$, and the exposure $x$ is causally related to an outcome $y$. Thus,

$$
\begin{aligned}
g & \sim Binom(2, 0.5) \\
x & = \alpha_g + \beta_g g + \epsilon_g \\
y & = \alpha_x + \beta_x x + \epsilon_x \\
\end{aligned}
$$

The following tests are then performed:

1. $H_0: cov(g, x) = 0; H_1: cov(g, x) \neq 0$; *the SNP associates with the exposure*
2. $H_0: cov(g, y) = 0; H_1: cov(g, y) \neq 0$; *the SNP associates with the outcome*
3. $H_0: cov(x, y) = 0; H_1: cov(x, y) \neq 0$; *the exposure associates with the outcome*
4. $H_0: cov(g, y - \hat{y}) \neq 0; cov(g, y - \hat{y}) = 0$; *the SNP is independent of the outcome when the outcome is adjusted for the exposure*

where $y - \hat{y} = y - \hat{alpha}_g + \hat{\beta}_g x$ is the residual of $y$ after adjusting for the $x$, where $x$ is assumed to mediate the association between the SNP and the outcome. If all four tests reject the null hypothesis then it is inferred that $x$ is causally related to $y$. The CIT measures the strength of causality by generating an omnibus p-value, $p_{CIT}$, which is simply the largest (least extreme) p-value of the four tests, the intuition being that causal inference is only as strong as the weakest link in the chain of tests.

In these analyses the *cit.cp* function was used to obtain an omnibus p-value. To infer the direction of causality using the CIT method, an omnibus p-value generated by CIT, $p_{CIT}$, was estimated for the correct model of $x$ causing $y$, and for incorrect model of $y$ causing $x$. For some significance threshold $\alpha$, the existence of causality and its direction was inferred based on the following scenarios:

- If $p_{CIT,correct} < \alpha$ and $p_{CIT,incorrect} > \alpha$ then the correct model is accepted
- If $p_{CIT,correct} > \alpha$ and $p_{CIT,incorrect} < \alpha$ then the incorrect model is accepted
- If $p_{CIT,correct} > \alpha$ and $p_{CIT,incorrect} > \alpha$ then an alternative causal model is accepted
- If $p_{CIT,correct} < \alpha$ and $p_{CIT,incorrect} < \alpha$ then no inference is made

For the purposes of compiling simulation results we use an arbitrary $\alpha = 0.05$ value, though we should stress that for real analyses it is not good practice to use p-values for making causal inference, nor is it reliable to depend on arbitrary significance thresholds.


### MR causal test

Two stage least squares (2SLS) is a commonly used technique for performing MR when the exposure, outcome and instrument data are all available in the same sample. Assuming the following model

$$
y = \alpha_{MR} + \beta_{MR} \hat{x} + \epsilon_{MR}
$$

where $\hat{x} = \hat{\alpha}_g + \hat{\beta}_g g$, a causal relationship is inferred if the null hypothesis that $\beta_{MR} = 0$ is rejected. A p-value for this test, $p_{MR}$, was obtained using the R package $R/systemfit$.

The direction of the causal association was inferred as follows. Assuming no horizontal pleiotropy (i.e. $g$ only has an effect on one of the variables through the other variable) it is desirable to know which of the variables, $x$ or $y$, it has a direct influence on. This can be achieved by assessing which of the two variables has the biggest absolute correlation with $g$ (Appendix 2). This test can be formalised by testing for a difference in the correlations $\rho_{gx}$ and $\rho_{gy}$ using Steiger's Z-test for correlated correlations within a population [@Steiger1980]. It is calculated as

$$
Z = (Z_{gx} - Z_{gy}) \frac{\sqrt{N-3}}{\sqrt{2(1-\rho_{xy})h}}
$$

where Fisher's z-transformation is used to obtain $Z_{g*} = \frac{1}{2} \ln  \left (  \frac{1+\rho_{g*}}{1-\rho_{g*}} \right )$,

$$
h = \frac{1 - (frm^2)} {1 - rm^2}
$$

where

$$
f = \frac{1 - \rho_{xy}}{2(1 - rm^2)}
$$

and 

$$
rm^2 = \frac{1}{2}(\rho_{gx}^2 + \rho_{gy}^2).
$$

The $Z$ value is interpreted such that 

$$
Z \left\{
\begin{array}{ll}
> 0, & x \to y\\
< 0, & y \to x\\
= 0, & x \perp\!\!\!\perp y 
\end{array} \right.
$$

and a p-value is generated from the $Z$ value to indicate the probability of obtaining the observed difference in correlations $\rho_{gx}$ and $\rho_{gy}$ under the null hypothesis that both correlations are identical. The existence of causality and its direction is inferred based on the following scenarios:

- If $p_{Steiger} < \alpha$ and $p_{MR} < \alpha$ and $Z > 0$ then a causal association for the correct model is accepted
- If $p_{Steiger} < \alpha$ and $p_{MR} < \alpha$ and $Z < 0$ then a causal association for the incorrect model is accepted
- Otherwise no inference is made

For the purposes of compiling simulation results, we use an arbitrary $\alpha = 0.05$ value.

Note that the same correlation test approach can be applied to a two-sample MR [@Pierce2013] setting, where the Steiger test of two independent correlations is applied instead of the case detailed here where correlations share one variable in common. An advantage of using the Steiger test in the two sample context is that it can compare correlations in independent samples where sample sizes are different. The method and R function are provided in Appendix 3.


### Simulations

Simulations were conducting by creating variables of sample size $n$ for the exposure $x$, the measured values of the exposure $x_O$, the outcome $y$, the measured values of the outcome $y_O$ and the instrument $g$. In all models $x$ causes $y$ and $g$ is an instrument for $x$. Each variable was simulated such that:

$$
\begin{aligned}
g & \sim Binom(2, 0.5) \\
x & = \alpha_g + \beta_g g + \epsilon_g \\
x_O & = \alpha_{mx} + \beta_{mx} x + \epsilon_{mx} \\
y & = \alpha_x + \beta_x x + \epsilon_x \\
y_O & = \alpha_{my} + \beta_{my} y + \epsilon_{my} \\
\end{aligned}
$$

where $\epsilon_{m*} \sim N(0, \sigma^2_{m*})$, and $*_{mx}$ are parameters that represent non-differential measurement error into the exposure variable $x$, and $*_{my}$ are parameters for non-differential measurement error in the outcome $y$.

All $\alpha$ values were set to 0, and $\beta$ values set to 1. Values of $\epsilon_*$ were generated such that 

$$
\begin{aligned}
cor(g, x)^2 & = 0.1 \\
cor(x, y)^2 & = \{0.2, 0.4, 0.6, 0.8\} \\
\sigma^2_{mx} & = \{0, 0.2, 0.4, 0.6, 0.8, 1\} \\
\sigma^2_{my} & = \{0, 0.2, 0.4, 0.6, 0.8, 1\} \\
n & = \{100, 1000, 10000\}
\end{aligned}
$$

giving a total of 432 combinations of parameters. Simulations using each of these sets of variables were performed 100 times, and the CIT and MR methods were applied to each in order to evaluate the causal association of the simulated variables. Similar patterns of results were obtained for different values of $cor(g, x)$.

## Results

### The influence of measurement error on mediation

Measurement error of an exposure can be modeled as some transformation of the true value that leads to the observed value, $x_O = f(x)$. For example, we can define $f(x) = \alpha_{mx} + \beta_{mx} x + \epsilon_{mx}$, where $\alpha_{mx}$ and $\beta_{mx}$ influence the error in the measurement of $x$, and $\epsilon_{mx}$ represents the imprecision in the measurement of $x$. Here the true value of the exposure is partially explained by the genetic instrument, $g$, such that

$$
x = \alpha_g + \beta_g g + \epsilon_g
$$

where $\beta_g$ is the effect of the SNP on the exposure, and $\epsilon_g$ is the normally distributed residual value of $x$; and the outcome is partially explained by the exposure

$$
y = \alpha_x + \beta_x x + \epsilon_x
$$

where $\beta_x$ is the true effect of the exposure on the outcome. In the causal inference test (CIT), an omnibus p-value is generated from four hypothesis tests: 1) $g$ is associated with $x$; 2) $g$ is associated with $y$; 3) $x$ is associated with $y$; and 4) $g$ is independent of $y|x$. The 4th condition is necessary for causal inference, and can be expressed as $cov(g, y - \hat{y}) = 0$, where $\hat{y} = \hat{\alpha}_x + \hat{\beta}_x x_O$. When measurement error is introduced we can show using basic covariance properties (Appendix 1) that

$$
\begin{aligned}
cov(g, y - \hat{y}) & = cov(g, y_O) - cov(g, \hat{y}_O)  \\
                    & = \beta_{my} \beta_g \beta_x var(g) - D \beta_{my} \beta_g \beta_x var(g)
\end{aligned}
$$

where

$$
D = \frac{\beta^2_{mx} var(x)} {\beta^2_{mx} var(x) + var(\epsilon_{mx})}
$$

Thus an observational study will find $cov(g, y_O - \hat{y_O}) = 0$ when the true model is causal only when $D = 1$. Therefore, if there is any measurement error that incurs imprecision (i.e. $var(\epsilon_{mx}) \neq 0$) then there will remain an association between $g$ and $y_O | x$, which is in violation of the the 4th condition of the CIT. Note that linear transformation of $x$ or $y$ without any incurred imprecision is insufficient to lead to a violation of the test statistic assumptions.

We performed simulations to verify that this problem does arise using the CIT method. `r cfig("cit_measurement_error_figure")` shows that when there is no measurement error in the exposure or outcome variables ($\rho_{x, x_O}=1$) the CIT is reliable in identifying the correct causal direction. However, as measurement error increases in the exposure variable, eventually the CIT is more likely to infer a robust causal association in the wrong direction. Also of concern here is that increasing sample size does not solve the issue, indeed it only strengthens the apparent evidence for the incorrect inference.


### Inferring the existence of causality

When selecting an instrument $g$ that has a direct influence on $x$ and $x$ is causally related to $y$, one can reason that the influence of $g$ on $y$ is the proportion of the effect of $x$ on $y$ that is explained by the effect of $g$ on $x$. Hence the effect estimate $\beta_{MR}$ of $x$ on $y$ is estimated as

$$
\begin{aligned}
\beta_{MR} = \frac{\beta_{y_O}}{\beta_g} & = \frac{cov(y_O, g)}{cov(x_O, g)} \\
                                         & = \frac{\beta_{my} \beta_x cov(x, g)} {\beta_{mx} cov(x, g)} \\
                                         & = \frac{\beta_{my}} {\beta_{mx}} \beta_x
\end{aligned}
$$

Thus we obtain an estimate of the effect of $x_O$ on $y$ that is scaled by the measurement error in $x$ and $y$, but is unrelated to measurement imprecision. Measurement error and imprecision are likely to reduce the power of MR inferring a causal association (increased false negative rate), but importantly the evidence for causal association, based on rejecting the null hypothesis that $\beta_{MR} = 0$, is not inflated when the null hypothesis is true.

We performed simulations to compare the performance of MR against CIT in detecting a causal association between simulated variables under different levels of imprecision simulated in the exposure. `r cfig("causality_exists_tpr")` shows the true positive rates between the CIT and MR for detecting a causal association. We observe that the CIT has lower power in all cases, with performance declining as measurement imprecision increases in the exposure. The performance of MR in detecting an association is unrelated to measurement error in. Measurement error in the outcome does not induce a substantive difference in performance between CIT and MR.


### Inferring the direction of causality

If we do not know whether the SNP $g$ has a direct influence on $x$ or $y$ then further efforts are required. If $x$ causes $y$ and $g$ is a valid instrument for $x$ then we expect that the Steiger test will obtain the correct result. This is because the value $d = \rho_{g, x_O} - \rho_{g, y_O}$ is greater than 0 when the causal association between $x$ and $y$ is $\rho_{x, y} < 1$. But it can be shown that in the presence of measurement error, $d = \rho_{x, x_O} - \rho_{x,y}\rho_{y,y_O}$ (Appendix 2), thus it is important to note that under certain conditions when measurement error is present the Steiger test could make erroneous inference about causal direction because the value of $d$ is not restricted to being greater than 0. However, using the MR approach there are two potential advantages over the CIT. First, we can conduct a formal test for the direction of causality. Second the correct direction of causality can be inferred when measurement error in the exposure variable is present, as long as it is lower than the product of the measurement error in the outcome and the causal correlation between the exposure and the outcome. `r cfig("d_relationship_figure")` shows that in most cases, especially when the causal effect between $x$ and $y$ is not very large, the condition of $d > 0$ is satisfied.

We performed simulations to explore the performance of this approach in comparison to CIT. `r cfig("cit_mr_comparison_figure")` shows that, as predicted, when $d < 0$ the MR analysis is liable to infer the wrong direction of causality, and that this erroneous result is more likely to occur with increasing sample size. However, in a large number of cases the MR analysis infers the wrong direction of causality at a much lower rate than the CIT. When $d > 0$ is satisfied we observe that in most cases the MR method has greater power to obtain evidence for causality than CIT, and always obtains the correct direction of causality.


## Discussion

Researchers are often confronted with the problem of making causal inferences using a statistical framework on observational data, and unfortunately there are no solutions that work perfectly in all scenarios. In the face of measurement error it is evident that causal inference drawn through mediation analysis will be difficult to interpret, and this is a serious problem considering that it is often impossible to estimate the extent of measurement error for most experimental designs. 

In the epidemiological literature this is relatively well understood and our initial analysis simply confirms that for widely used methods such as CIT they are indeed liable to the same issues as standard mediation based analysis. Specifically, we show that as measurement error in the exposure variable increases, CIT is likely to infer the wrong direction of causality. We also demonstrate that, though seemingly unintuitive, increasing sample size does not resolve the issue, rather it increases the significance of the incorrect inference. 

Under many circumstances a practical solution to this problem is to use Mendelian randomisation instead of mediation based methods. Mendelian randomisation is robust in the face of measurement error and, given that the researcher has knowledge about the biology of the instrument being used in the analysis, can offer a direct solution to the issues that CIT faces. This assumption is often reasonable, for example SNPs are commonly used as instruments when they are found in genes with known biological relevance to the trait of interest. But on many occasions this is not the case, and it may be tempting to resort to using methods based on mediation in order to be able to both ascertain if there is a causal association and to infer the direction of causality. Here we have described a simple extension to MR which can be used as an alternative to mediation based methods. We show that this method is still liable to measurement error, but because it has different properties to the CIT it offers two main advantages. First, it uses a formal statistical framework to test for the robostness of the assumed direction of causality. Second, after testing in a comprehensive range of scenarios the MR based approach is less likely to infer the wrong direction of causality compared to CIT, while substantially improving power over CIT in the cases where $d > 0$.

Mediation based network approaches are very well established [@Lagani2015] and have a number of extensions that make them valuable tools, including for example network construction. But because they are predicated on the basic underlying principles of mediation they are liable to suffer from the same issues of measurement error. Recent advances in MR methodology, for example network MR [@Burgess2015] and mediation through MR [@Varbo2015] may offer more robust solutions alternatives for these more complicated problems.

There are a number of limitations to the analysis that we performed. We focused on the simple case of a single instrument in a single sample setting, and assumed that pleiotropy (the influence of the instrument on the outcome through a mechanism other than the exposure) was not present. To give an example in which this might arise consider the case that C-reactive protein (CRP) is being tested for causal association with some outcome, and the FTO variant is used as an instrument. Though FTO is robustly associated with CRP, it is through the upstream influence of BMI [@Timpson2011]. Thus, if BMI has a direct influence on the outcome, the conditions of MR will be violated and the Steiger test proposed here will be unreliable.

The overarching result from our simulations is that, regardless of the method used, inferring causal direction using an instrument of unknown biology is very susceptible to measurement error. With the presence of measurement error near ubiquitous in most cross sectional studies, and our ability to measure it limited, we argue that it should be given serious consideration in designing statistical analyses that attempt to make causal inference, and that any putitive results should be accompanied with appropriate sensitivity analysis that assesses their robustness under varying levels of measurement error.


\newpage

## Figures

```{r cit_measurement_error_figure, fig.width=10, fig.height=10 }

```	

`r fig_nums("cit_measurement_error_figure")`

\newpage


```{r d_relationship_figure, fig.width=10, fig.height=6 }

```

`r fig_nums("d_relationship_figure")`

\newpage


```{r cit_mr_comparison_figure, fig.width=10, fig.height=10 }

```

`r fig_nums("cit_mr_comparison_figure")`

\newpage


## Appendix 1

We assume the following model

$$
\begin{aligned}
x   & = \alpha_g + \beta_g g + \epsilon_g \\
x_O & = \alpha_m + \beta_m x + \epsilon_m \\
y   & = \alpha_x + \beta_x x + \epsilon_x \\
y_O & = \alpha_n + \beta_n y + \epsilon_n
\end{aligned}
$$

where $x$ is the exposure on the outcome $y$, $g$ is an instrument that has a direct effect on $x$, $x_O$ is the measured quantity of $x$, where measurement error is incurred from bias in $\alpha_m$ and $\beta_m$ and imprecision from $\epsilon_m$, and $y_O$ is the measured quantity of $y$, where measurement error is incurred from bias in $\alpha_n$ and $\beta_n$ and imprecision from $\epsilon_n. Our objective is to estimate the expected magnitude of association between $g$ and $y$ after conditioning on $x$. Under the CIT, this is expected to be $cov(g, y_O - \hat{y}_O) = 0$ when $x$ causes $y$, where $\hat{y}_O = \hat{a}_{x_O} + \hat{\beta}_{x_O} x_O$ is the predicted value of $y_O$ using the measured value of $x_O$.

We can split $cov(g, y_O - \hat{y}_O)$ into two parts, $cov(g, y_O)$ and $cov(g, \hat{y}_O)$.

**Part 1**

$$
\begin{aligned}
cov(g, y_O) & = cov(g, \beta_n y) \\
            & = cov(g, \beta_n \beta_x x) \\
            & = cov(g, \beta_n \beta_x \beta_g g) \\
            & = \beta_n \beta_x \beta_g var(g)
\end{aligned}
$$

**Part 2**

$$
\begin{aligned}
cov(g, \hat{y}_O) & = cov(g, \hat{\beta}_{x_O} x_O) \\
                  & = cov(g, \hat{\beta}_{x_O} \beta_m x) \\
                  & = cov(g, \hat{\beta}_{x_O} \beta_m \beta_g g) \\
                  & = \hat{\beta}_{x_O} \beta_m \beta_g var(g)
\end{aligned}
$$

Simpifying further

$$
\begin{aligned}
\hat{\beta}_{x_O} & = \frac{cov(y_O, x_O)} {var(x_O)} \\
                  & = \frac{cov(\beta_n y, \beta_m x)} {\beta_m^2 var(x) + var(\epsilon_m)} \\
                  & = \frac{\beta_m \beta_n cov(y, x)} {\beta_m^2 var(x) + var(\epsilon_m)} \\
                  & = \frac{\beta_m \beta_n \beta_x var(x)} {\beta_m^2 var(x) + var(\epsilon_m)}
\end{aligned}
$$

which can be substituted back to give

$$
\begin{aligned}
cov(g, \hat{y}_O) & = \frac{\beta_n \beta_x \beta_g var(g) \beta_m^2 var(x)} {\beta_m^2 var(x) + var(\epsilon_m)} \\
                  & = \frac{\beta_m^2 var(x)} {\beta_m^2 var(x) + var(\epsilon_m)} \times \beta_n \beta_x \beta_g var(g)
\end{aligned}
$$

Finally

$$
\begin{aligned}
cov(g, y_O - \hat{y}_O) & = \beta_n \beta_x \beta_g var(g) - \frac{\beta_m^2 var(x)} {\beta_m^2 var(x) + var(\epsilon_m)} \times \beta_n \beta_x \beta_g var(g)
\end{aligned}
$$

thus $cov(g, y_O - \hat{y}_O) = 0$ if the measurement imprecision in $x_O$ is $var(\epsilon_m) = 0$. However if there is any imprecision then the condition $cov(g, y_O - \hat{y}_O) = 0$ will not hold.

\newpage

## Appendix 2

The Steiger test is used to infer if the variant $g$ has a direct influence on $x$ or $y$ when it is known that it associates with both, but the direction of causality between $x$ and $y$ is unknown. Assuming the causal direction is $x \to y$, two stage MR is formulated using the following regression models:

$$
x = \alpha_1 + \beta_1 g + e_1
$$

for the first stage and

$$
y = \alpha_2 + \beta_2 \hat{x} + e_2
$$

where $\hat{x} = \hat{alpha}_1 + \hat{\beta}_1 g$. Writing in scale free terms, $\rho_{g, x}$ denotes the correlation between $g$ and the exposure variable $x$, and it is expected that $\rho_{g, x} > \rho_{g, y}$ because $\rho_{g, y} = \rho_{g, x}\rho_{x, y}$, where $\rho_{x, y}$ is the causal association between $x$ and $y$ (which is likely to be less than 1). In the presence of measurement error in $x$ and $y$, however, Steiger test will instead be assessing the inequality $\rho_{g, x_O} > \rho_{g, y_O}$, which can be simplified:

$$
\begin{aligned}
\rho_{g, x_O} & > \rho_{g, y_O} \\
\rho_{g, x} \rho_{x, x_O} & > \rho_{g,y}\rho_{y,y_O}\\
\rho_{g, x} \rho_{x, x_O} & > \rho_{g,x}\rho_{x,y}\rho_{y,y_O}\\
\rho_{x, x_O} & > \rho_{x,y}\rho_{y,y_O}
\end{aligned}
$$


\newpage




## References
